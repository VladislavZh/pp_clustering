# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18eWcA2mo_UgFe6qVOPtTV1VSCmsYaW5v
"""

import os
import json
import torch
import numpy as np
import pandas as pd
from utils.metrics import purity
from utils.data_preprocessor import get_dataset
import tsfresh
from sklearn.cluster import DBSCAN
from sklearn.cluster import KMeans
from sklearn.cluster import AffinityPropagation
from sklearn import mixture
import time


def check_dataset(path_to_data, n_classes, n_steps, n_clusters, n_runs):
    t1 = time.time()
    data, target = get_dataset(path_to_data, n_classes, n_steps)
    n_classes += 1
    N = data.shape[0]
    data_divided = []
    for i in range(n_classes):
        data_divided.append(data[:, :, i].reshape(-1))
    to_extract = []
    for i in range(n_classes):
        ids = np.arange(N).repeat(n_steps)
        tmp = np.vstack((ids, data_divided[i]))
        tmp = tmp.T
        to_extract.append(pd.DataFrame(data=tmp, columns=["id", "value"]))
    tfs = []
    for i in range(n_classes):
        tf = tsfresh.extract_features(to_extract[i], column_id="id")
        tfs.append(tf)
    data_feat = pd.concat(
        [tfs[i].reindex(tfs[0].index) for i in range(n_classes)], axis=1
    )
    data_feat.fillna(0, inplace=True)
    data_feat.replace([np.inf, -np.inf], 0, inplace=True)
    t2 = time.time()
    kmeans_purs = []
    aff_purs = []
    gmm_purs = []
    dbscan_purs = []

    model = KMeans(n_clusters=n_clusters)
    model.fit(data_feat)
    clusters = model.predict(data_feat)
    kmeans_purs.append(purity(torch.Tensor(clusters), target))
    t3 = time.time()

    clustering = AffinityPropagation().fit(data_feat)
    clusters = clustering.labels_
    aff_purs.append(purity(torch.Tensor(clusters), target))
    t4 = time.time()

    g = mixture.GaussianMixture(n_components=2)
    g.fit(data_feat)
    clusters = g.predict(data_feat)
    gmm_purs.append(purity(torch.Tensor(clusters), target))
    t5 = time.time()

    dbscan = DBSCAN()
    dbscan.fit(data_feat)
    clusters = dbscan.labels_
    dbscan_purs.append(purity(torch.Tensor(clusters), target))

    t6 = time.time()

    for i in range(n_runs - 1):
        model = KMeans(n_clusters=n_clusters)
        model.fit(data_feat)
        clusters = model.predict(data_feat)
        kmeans_purs.append(purity(torch.Tensor(clusters), target))

        clustering = AffinityPropagation().fit(data_feat)
        clusters = clustering.labels_
        aff_purs.append(purity(torch.Tensor(clusters), target))

        g = mixture.GaussianMixture(n_components=2)
        g.fit(data_feat)
        clusters = g.predict(data_feat)
        gmm_purs.append(purity(torch.Tensor(clusters), target))

        dbscan = DBSCAN()
        dbscan.fit(data_feat)
        clusters = dbscan.labels_
        dbscan_purs.append(purity(torch.Tensor(clusters), target))

    print(
        "Running time: FE = {}, KMeans = {}, Aff = {}, GMM = {}, DBSCAN = {}".format(
            t2 - t1,
            t3 - t2 + t2 - t1,
            t4 - t3 + t2 - t1,
            t5 - t4 + t2 - t1,
            t6 - t5 + t2 - t1,
        )
    )
    print("KMeans purity:", np.mean(kmeans_purs), "+-", np.std(kmeans_purs))
    print("AffinityPropagation purity:", np.mean(aff_purs), "+-", np.std(aff_purs))
    print("GMM purity:", np.mean(gmm_purs), "+-", np.std(gmm_purs))
    print("DBSCAN purity:", np.mean(dbscan_purs), "+-", np.std(dbscan_purs))
    res_dict = {}
    res_dict["data"] = path_to_data
    res_dict["n_classes"] = n_classes
    res_dict["n_steps"] = n_steps
    res_dict["n_clusters"] = n_clusters
    res_dict["n_runs"] = n_runs
    res_dict["kmeans"] = {
        "mean": np.mean(kmeans_purs),
        "std": np.std(kmeans_purs),
        "time": t3 - t2 + t2 - t1,
    }
    res_dict["affinprop"] = {
        "mean": np.mean(aff_purs),
        "std": np.std(aff_purs),
        "time": t4 - t3 + t2 - t1,
    }
    res_dict["gmm"] = {
        "mean": np.mean(gmm_purs),
        "std": np.std(gmm_purs),
        "time": t5 - t4 + t2 - t1,
    }
    res_dict["dbscan"] = {
        "mean": np.mean(dbscan_purs),
        "std": np.std(dbscan_purs),
        "time": t6 - t5 + t2 - t1,
    }

    return res_dict


if __name__ == "__main__":
    
    res_maindir = "/pp_clustering/experiments/new_ablation_study"
    print(res_maindir)
    if not os.path.exists(res_maindir):
        os.makedirs(res_maindir)
    data_path = "data/trunc_K3_C5"
    n_classes = int(data_path[-1])
    n_steps = 128
    n_clusters = int(data_path[-4])
    n_runs = 5
    start_time = time.time()
    res_dict = check_dataset("data/K4_C5", n_classes, n_steps, n_clusters, n_runs)
    print("processed data", data_path, "finished")
    # saving results
    res_path = os.path.join(res_maindir, data_path.split("/")[-1])
    if not os.path.exists(res_path):
        os.makedirs(res_path)
    json_path = res_path + "/results_" + str(n_steps) + ".json"
    with open(json_path, "w") as fp:
        json.dump(res_dict, fp)
    print("results were saved to", res_path)
    print("total time", time.time() - start_time)

