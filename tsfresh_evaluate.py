# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18eWcA2mo_UgFe6qVOPtTV1VSCmsYaW5v
"""

import argparse
import os
import json
import torch
import numpy as np
import pandas as pd
from utils.metrics import purity
from utils.data_preprocessor import get_dataset
import tsfresh
from sklearn.cluster import DBSCAN
from sklearn.cluster import KMeans
from sklearn.cluster import AffinityPropagation
from sklearn import mixture
import time


def check_dataset(path_to_data, n_classes, n_steps, n_clusters):
    t1 = time.time()
    data, target = get_dataset(path_to_data, n_classes, n_steps)
    n_classes += 1
    N = data.shape[0]
    data_divided = []
    for i in range(n_classes):
        data_divided.append(data[:, :, i].reshape(-1))
    to_extract = []
    for i in range(n_classes):
        ids = np.arange(N).repeat(n_steps)
        tmp = np.vstack((ids, data_divided[i]))
        tmp = tmp.T
        to_extract.append(pd.DataFrame(data=tmp, columns=["id", "value"]))
    tfs = []
    for i in range(n_classes):
        tf = tsfresh.extract_features(to_extract[i], column_id="id")
        tfs.append(tf)
    data_feat = pd.concat(
        [tfs[i].reindex(tfs[0].index) for i in range(n_classes)], axis=1
    )
    data_feat.fillna(0, inplace=True)
    data_feat.replace([np.inf, -np.inf], 0, inplace=True)
    t2 = time.time()

    model = KMeans(n_clusters=n_clusters)
    model.fit(data_feat)
    kmeans_clusters = model.predict(data_feat)
    t3 = time.time()

    clustering = AffinityPropagation().fit(data_feat)
    ap_clusters = clustering.labels_
    t4 = time.time()

    g = mixture.GaussianMixture(n_components=2)
    g.fit(data_feat)
    gmm_clusters = g.predict(data_feat)
    t5 = time.time()

    dbscan = DBSCAN()
    dbscan.fit(data_feat)
    dbscan_clusters = dbscan.labels_

    t6 = time.time()

    res_dict = {}
    res_dict["data"] = path_to_data
    res_dict["n_classes"] = n_classes
    res_dict["n_steps"] = n_steps
    res_dict["n_clusters"] = n_clusters
    res_dict["kmeans"] = {
        "clusters": kmeans_clusters,
        "time": round(t3 - t2 + t2 - t1, 5),
    }
    res_dict["ap"] = {
        "clusters": ap_clusters,
        "time": round(t4 - t3 + t2 - t1, 5),
    }
    res_dict["gmm"] = {
        "clusters": gmm_clusters,
        "time": round(t5 - t4 + t2 - t1, 5),
    }
    res_dict["dbscan"] = {
        "clusters": dbscan_clusters,
        "time": round(t6 - t5 + t2 - t1, 5),
    }

    return res_dict


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", type=str, default="K3_C5")
    parser.add_argument("--experiment_n", type=str, default="0")
    args = parser.parse_args()
    # path to dataset
    datapath = os.path.join("data", args.dataset)
    # path to experiments settings
    experpath = os.path.join("experiments", args.dataset)
    experpath = os.path.join(experpath, "exp_" + args.experiment_n)
    with open(os.path.join(experpath, "args.json")) as json_file:
        config = json.load(json_file)
    n_steps = config["n_steps"]
    n_classes = config["n_classes"]
    n_clusters = config["true_clusters"]

    res_dict = check_dataset(datapath, n_classes, n_steps, n_clusters)
    # saving results
    res_df = pd.read_csv(os.path.join(experpath, "inferredclusters.csv"))
    res_df["kmeans_clusters"] = res_dict["kmeans"]["clusters"].tolist()
    res_df["kmeans_time"] = res_dict["kmeans"]["time"]
    res_df["ap_clusters"] = res_dict["ap"]["clusters"].tolist()
    res_df["ap_time"] = res_dict["ap"]["time"]
    res_df["gmm_clusters"] = res_dict["gmm"]["clusters"].tolist()
    res_df["gmm_time"] = res_dict["gmm"]["time"]
    res_df["dbscan_clusters"] = res_dict["dbscan"]["clusters"].tolist()
    res_df["dbscan_time"] = res_dict["dbscan"]["time"]

    savepath = os.path.join(experpath, "compareclusters.csv")
    res_df.drop(
        res_df.columns[res_df.columns.str.contains("unnamed", case=False)],
        axis=1,
        inplace=True,
    )
    res_df.to_csv(savepath)
